version: '3.8'

services:
  postgres:
    image: postgres:15.3-alpine
    ports:
      - "5432:5432"
    volumes:
      - postgres:/data/postgres
      # Create multiple databases with users upon starting
      # See https://github.com/mrts/docker-postgresql-multiple-databases#using-multiple-databases-with-the-official-postgresql-docker-image
      # Remember to grant execution to your script: "chmod +x <yourScript>"
      - ./postgres-scripts:/docker-entrypoint-initdb.d
    networks:
      - infra
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      PGDATA: /data/postgres
      POSTGRES_MULTIPLE_DATABASES: "product"
    # Create healthcheck for Postgres
    # See https://stackoverflow.com/questions/65115627/safe-ways-to-specify-postgres-parameters-for-healthchecks-in-docker-compose#72175755
    healthcheck:
      test: ["CMD-SHELL", "pg_isready", "-d", "db_prod"]
      interval: 30s
      timeout: 60s
      retries: 5
      start_period: 80s

  kafka0:
    image: docker.io/bitnami/kafka:3.4
    ports:
      - "9092"
      - "9093"
      # Map the container's port 9094 to the host machine's port 9094 for external clients to connect
      - "9094:9094"
    volumes:
      - "kafka0-data:/bitnami"
    networks:
      - infra
    environment:
      # Show debug logs
      BITNAMI_DEBUG: 1
      # Plaintext listener means the listener is without authentication and non-encrypted. Used for development only.
      ALLOW_PLAINTEXT_LISTENER: "yes"
      # A list of Kafka brokers in a quorum
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: "0@kafka0:9093"
      # Broker ID
      KAFKA_CFG_NODE_ID: 0
      # Cluster ID is created by "kafka-storage random-uuid"
      KAFKA_KRAFT_CLUSTER_ID: "qYoMEZXcS_SKP2PzAl8-WA"

      # Bitnami has configured:
      # + "listeners" as "PLAINTEXT://:9092,CONTROLLER://:9093".
      # + "advertised.listeners" as "PLAINTEXT://:9092"
      # See https://github.com/bitnami/containers/blob/main/bitnami/kafka/README.md#configuration
      # "listeners" is what the broker will use to create server sockets.
      # "advertised.listeners" is what clients will use to connect to the brokers.

      # Override the default configuration values to expose INTERNAL and EXTERNAL listeners.
      # Otherwise, EXTERNAL listener allows external clients like ProductApp to connect.
      # See https://github.com/bitnami/containers/blob/main/bitnami/kafka/README.md#accessing-apache-kafka-with-internal-and-external-clients
      KAFKA_CFG_LISTENERS: "INTERNAL://:9092,CONTROLLER://:9093,EXTERNAL://:9094"
      KAFKA_CFG_ADVERTISED_LISTENERS: "INTERNAL://kafka0:9092,EXTERNAL://localhost:9094"

      # Map between listener names and security protocols.
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT"
      # Name of listener used for communication between brokers.
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: "INTERNAL"

  schema-registry:
    image: confluentinc/cp-schema-registry:7.3.0
    ports:
      # Map the container's port 8081 to the host machine's port 8081 for the localhost's ProductApp can connect
      - "8081:8081"
    depends_on:
      - kafka0
    networks:
      - infra
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka0:9092"
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"
      SCHEMA_REGISTRY_URL: "http://localhost:8081"

  product:
    build:
      context: .
      dockerfile: Dockerfile
    image: product:1.0-SNAPSHOT
    ports:
      - 50001:8080
    depends_on:
      postgres:
        condition: service_healthy
      kafka0:
        condition: service_started
    networks:
      - infra

networks:
  infra:
    driver: bridge

volumes:
  postgres:
  kafka0-data:
